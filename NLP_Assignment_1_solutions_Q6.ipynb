{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Assignment 1 (40% of grade): Text classification for Fake News Detection - SOLUTION Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv                               # csv reader\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier, NaiveBayesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from random import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful libraries\n",
    "from nltk.stem import WordNetLemmatizer  # lemmatization\n",
    "import nltk # for accessing the stopwords etc.\n",
    "import re # regex\n",
    "import string # other string operations\n",
    "from textblob import TextBlob # for spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different pre-processing techniques which get called altogether by pre_process\n",
    "\n",
    "# method to deal with number words being normalized to digits \n",
    "\n",
    "def text2int(textnum, numwords={}):\n",
    "    if not numwords:\n",
    "        units = [\n",
    "        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n",
    "        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n",
    "        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\",\n",
    "        ]\n",
    "\n",
    "        tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n",
    "\n",
    "        scales = [\"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n",
    "\n",
    "        numwords[\"and\"] = (1, 0)\n",
    "        for idx, word in enumerate(units):  numwords[word] = (1, idx)\n",
    "        for idx, word in enumerate(tens):       numwords[word] = (1, idx * 10)\n",
    "        for idx, word in enumerate(scales): numwords[word] = (10 ** (idx * 3 or 2), 0)\n",
    "\n",
    "    ordinal_words = {'first':1, 'second':2, 'third':3, 'fifth':5, 'eighth':8, 'ninth':9, 'twelfth':12}\n",
    "    ordinal_endings = [('ieth', 'y'), ('th', '')]\n",
    "\n",
    "    textnum = textnum.replace('-', ' ')\n",
    "\n",
    "    current = result = 0\n",
    "    curstring = \"\"\n",
    "    onnumber = False\n",
    "    for word in textnum.split():\n",
    "        if word in ordinal_words:\n",
    "            scale, increment = (1, ordinal_words[word])\n",
    "            current = current * scale + increment\n",
    "            if scale > 100:\n",
    "                result += current\n",
    "                current = 0\n",
    "            onnumber = True\n",
    "        else:\n",
    "            for ending, replacement in ordinal_endings:\n",
    "                if word.endswith(ending):\n",
    "                    word = \"%s%s\" % (word[:-len(ending)], replacement)\n",
    "\n",
    "            if word not in numwords:\n",
    "                if onnumber:\n",
    "                    curstring += repr(result + current) + \" \"\n",
    "                curstring += word + \" \"\n",
    "                result = current = 0\n",
    "                onnumber = False\n",
    "            else:\n",
    "                scale, increment = numwords[word]\n",
    "\n",
    "                current = current * scale + increment\n",
    "                if scale > 100:\n",
    "                    result += current\n",
    "                    current = 0\n",
    "                onnumber = True\n",
    "\n",
    "    if onnumber:\n",
    "        curstring += repr(result + current)\n",
    "\n",
    "    return curstring\n",
    "\n",
    "def tokenize_text(text):\n",
    "    if preprocessing_switches[\"separate_out_punctuation\"]:\n",
    "        text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text) # separates punctuation at ends of strings\n",
    "        text = re.sub(r\"([.,;:!?'\\\"“\\(\\)])(\\w)\", r\"\\1 \\2\", text) # separates punctuation at beginning of strings\n",
    "    if preprocessing_switches[\"convert_numbers\"]:\n",
    "        text = re.sub('\\d+', 'NUMBER',text)\n",
    "    # print(\"tokenising:\", text) # uncomment for debugging\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "def remove_characters_after_tokenization(tokens):\n",
    "    # note preserving critical social media/twitter characters @ and #\n",
    "    p = '[{}]'.format(re.escape(string.punctuation)+'\\…').replace(\"@\", \"\").replace(\"\\#\", \"\")\n",
    "    #print(p)\n",
    "    pattern = re.compile(p)\n",
    "    filtered_tokens = [f for f in filter(None, [pattern.sub('', token) for token in tokens])]\n",
    "    return filtered_tokens\n",
    "\n",
    "def convert_to_lowercase(tokens):\n",
    "    return [token.lower() for token in tokens if token.isalpha()]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    stopword_list = nltk.corpus.stopwords.words('english')\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    return filtered_tokens\n",
    "\n",
    "def apply_lemmatization(tokens, wnl=WordNetLemmatizer()):   \n",
    "    return [wnl.lemmatize(token) for token in tokens]\n",
    "\n",
    "def pre_process(text):\n",
    "    \"\"\" Technique which will apply the techniques if they are set to \n",
    "    True in the global dict ::preprocessing_switches::\n",
    "    \"\"\"\n",
    "    if preprocessing_switches[\"convert_usernames\"]:\n",
    "        text = re.sub(\"@[a-zA-Z0-9:.]+\", \"@username\", text)\n",
    "    if preprocessing_switches[\"convert_number_words_to_digits\"]:\n",
    "        text = text2int(text)\n",
    "    tokens = tokenize_text(text)\n",
    "    if preprocessing_switches[\"remove_punctuation\"]:\n",
    "        tokens = remove_characters_after_tokenization(tokens)\n",
    "    if preprocessing_switches[\"convert_to_lowercase\"]:\n",
    "        tokens = convert_to_lowercase(tokens)\n",
    "    if preprocessing_switches[\"remove_stopwords\"]:\n",
    "        tokens = remove_stopwords(tokens)\n",
    "    if preprocessing_switches[\"apply_lemmatization\"]:\n",
    "        tokens = apply_lemmatization(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change cross-val function to allow first fold only option\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def cross_validate(dataset, folds, first_fold_only=False):\n",
    "    results = []\n",
    "    fold_size = int(len(dataset)/folds) + 1\n",
    "    \n",
    "    for i in range(0,len(dataset),int(fold_size)):\n",
    "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
    "        print(\"Fold start on items %d - %d\" % (i, i+fold_size))\n",
    "        \n",
    "        fold_test_data = dataset[i:i+fold_size]   # get test split on this fold\n",
    "        fold_train_data = dataset[:i] + dataset[i+fold_size:] # get train split on this fold\n",
    "        classifier = train_classifier(fold_train_data) # train classifier on the training data\n",
    "        y_true = [x[1] for x in fold_test_data] # get ground-truth labels\n",
    "        y_pred = predict_labels([x[0] for x in fold_test_data], classifier) # use classifier to predict\n",
    "        results.append(precision_recall_fscore_support(y_true, y_pred, average='weighted')) # get results\n",
    "        # print(classification_report(y_true,y_pred))  # see classification report for fold\n",
    "        \n",
    "        #alternative: focus on the FAKE label accuracy only\n",
    "        #report = classification_report(y_true, y_pred, output_dict=True)\n",
    "        #results.append([report[\"FAKE\"]['precision'], report[\"FAKE\"]['recall'], report[\"FAKE\"]['f1-score']]) # focus on FAKE\n",
    "        if first_fold_only:\n",
    "            break # quicker version only using one fold\n",
    "        \n",
    "    avg_results = [np.mean([x[0] for x in results]),\n",
    "                   np.mean([x[1] for x in results]),\n",
    "                   np.mean([x[2] for x in results])\n",
    "                ]\n",
    "    return avg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now just use the answer to Q2 for feature extraction (unigram bow binary)\n",
    "global_feature_dict = {} # A global dictionary of features\n",
    "\n",
    "# Solution from Q5\n",
    "from collections import Counter\n",
    "\n",
    "def to_feature_vector(tokens):\n",
    "    # SOLUTION: a method to extract different ngram sequences from tokens\n",
    "    # and different weighting on those counts\n",
    "    \n",
    "    feature_vector_dict =  Counter()  # local feature vector for counts\n",
    "    \n",
    "    # collect the counts for all n in range (1,_N_)\n",
    "    for n in range(1,_N_+1):\n",
    "        new_tokens = [\"<s>\"]*(n-1) + tokens + [\"</s>\"]\n",
    "        for i in range(n-1, len(new_tokens)):\n",
    "            raw_ngram = \" \".join(new_tokens[i-(n-1):i+1])\n",
    "            #print(raw_ngram)\n",
    "            n_gram = \"{}@{}\".format(n, raw_ngram)\n",
    "            #print(n_gram)\n",
    "            feature_vector_dict[n_gram]+=1\n",
    "    \n",
    "    # if _WEIGHT_ is 'counts' then this has already been done\n",
    "    if _WEIGHT_ == \"binary\":\n",
    "        feature_vector_dict = {x:1 for x in feature_vector_dict.keys()}  # binary Set-of-Words\n",
    "    elif _WEIGHT_ == \"weighted\":\n",
    "        # bag-of-words counts \n",
    "        feature_vector_dict = {x:feature_vector_dict[x]/(len(tokens)+1) for x in feature_vector_dict.keys()}\n",
    "    \n",
    "    for feat,v in feature_vector_dict.items():\n",
    "        if not feat in global_feature_dict:\n",
    "            global_feature_dict[feat] = 1\n",
    "        else:\n",
    "            global_feature_dict[feat] +=1\n",
    "            \n",
    "    return feature_vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST SETTINGS FROM QUESTION 5\n",
    "# Best settings from joint optimization:\n",
    "_WEIGHT_ = 'counts'\n",
    "_N_ =  4\n",
    "preprocessing_switches = {'convert_usernames': False,\n",
    "  'separate_out_punctuation': False,\n",
    "  'convert_number_words_to_digits': False,\n",
    "  'convert_numbers': False,\n",
    "  'remove_punctuation': True,\n",
    "  'convert_to_lowercase': False,\n",
    "  'remove_stopwords': True,\n",
    "  'apply_lemmatization': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(data):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
    "    return SklearnClassifier(pipeline).train(data)\n",
    "\n",
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "def predict_labels(samples, classifier):\n",
    "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
    "    return classifier.classify_many(samples)\n",
    "\n",
    "def predict_label_from_raw(sample, classifier):\n",
    "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
    "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all combinations of pre-processing technique\n",
    "from itertools import chain, combinations  # for powerset, to get all combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6: Changing functions to extract other features from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            # create tuple of instance data with all 13 relevant fields\n",
    "            instance_data = parse_data_line(line)\n",
    "            raw_data.append(instance_data)\n",
    "                           \n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    \n",
    "    # adjusting to do preprocessing on the text only, using extra_features as a dictionary\n",
    "    for (text, label, extra_features) in raw_data[:num_training_samples]:\n",
    "        train_data.append((to_feature_vector(pre_process(text), extra_features), label))\n",
    "    for (text, label, extra_features) in raw_data[num_training_samples:]:\n",
    "        test_data.append((to_feature_vector(pre_process(text), extra_features), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    \"\"\"Converts the multiple classes into two,\n",
    "    making it a binary distinction between fake news and real.\"\"\"\n",
    "    #return label\n",
    "    # Converting the multiclass labels to binary labels\n",
    "    labels_map = {\n",
    "        'true': 'REAL',\n",
    "        'mostly-true': 'REAL',\n",
    "        'half-true': 'REAL',\n",
    "        'false': 'FAKE',\n",
    "        'barely-true': 'FAKE',\n",
    "        'pants-fire': 'FAKE'\n",
    "    }\n",
    "    return labels_map[label]\n",
    "\n",
    "\n",
    "def parse_data_line(data_line):\n",
    "    # Should return a tuple of the label as just FAKE or REAL and the statement\n",
    "    #print(data_line)\n",
    "    text = data_line[2]\n",
    "    label = convert_label(data_line[1])\n",
    "    header = [\"subject\", \"speaker\", \"speaker_job_title\", \"state_info\",\n",
    "              \"party_affiliation\", \"total_barely_true_counts\", \"total_false_counts\",\n",
    "              \"total_half_true_counts\", \"total_mostly_true_counts\",\n",
    "              \"total_pants_on_fire_counts\", \"context\"]\n",
    "    feat_values = data_line[3:]\n",
    "    extra_features = {feat_name: feat_value for feat_name,feat_value in zip(header,feat_values)}\n",
    "    return (text, label, extra_features)\n",
    "     \n",
    "    #return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "def train_classifier(data):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
    "    return SklearnClassifier(pipeline).train(data)\n",
    "\n",
    "def predict_labels(samples, classifier):\n",
    "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
    "    return classifier.classify_many(samples)\n",
    "\n",
    "def predict_label_from_raw(sample, classifier):\n",
    "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
    "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"subject\", \"speaker\", \"speaker_job_title\", \"state_info\",\n",
    "              \"party_affiliation\", \"total_barely_true_counts\", \"total_false_counts\",\n",
    "              \"total_half_true_counts\", \"total_mostly_true_counts\",\n",
    "              \"total_pants_on_fire_counts\", \"context\"]\n",
    "\n",
    "extra_feature_switches = {k: False for k in header}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_feature_vector(tokens, extra_features):\n",
    "    # Should return a dictionary containing features as keys, and weights as values\n",
    "  \n",
    "    feature_vector_dict =  Counter()\n",
    "    for n in range(1,_N_+1):\n",
    "        new_tokens = [\"<s>\"]*(n-1) + tokens + [\"</s>\"]\n",
    "        for i in range(n-1, len(new_tokens)):\n",
    "            raw_ngram = \" \".join(new_tokens[i-(n-1):i+1])\n",
    "            #print(raw_ngram)\n",
    "            n_gram = \"{}@{}\".format(n, raw_ngram)\n",
    "            #print(n_gram)\n",
    "            feature_vector_dict[n_gram]+=1\n",
    "    if _WEIGHT_ == \"binary\":\n",
    "        feature_vector_dict = {x:1 for x in feature_vector_dict.keys()}  # binary Set-of-Words\n",
    "    elif _WEIGHT_ == \"weighted\":\n",
    "        feature_vector_dict = {x:feature_vector_dict[x]/(len(tokens)+1) for x in feature_vector_dict.keys()}\n",
    "    elif _WEIGHT_ == 'counts':\n",
    "        feature_vector_dict = dict(feature_vector_dict)\n",
    "    extra_features = {k:v for k,v in extra_features.items() if extra_feature_switches[k]}\n",
    "    \n",
    "      # first filter according to whether the extra feature is on (being used or not)\n",
    "    # add all extra features except context\n",
    "    feature_vector_dict.update({k: v for k, v in extra_features.items() if k!=\"context\"})\n",
    "    \n",
    "    # add context counts/weights\n",
    "    if extra_feature_switches[\"context\"]:\n",
    "        context = extra_features[\"context\"]\n",
    "        context_tokens = pre_process(context)\n",
    "        context_counts = dict(Counter(context_tokens))\n",
    "        context_counts = {\"context_\" + word : count for word,count in context_counts.items()}\n",
    "        if _WEIGHT_ == \"binary\":\n",
    "            countext_counts = {x:1 for x in context_counts.keys()}  # binary Set-of-Words\n",
    "        elif _WEIGHT_ == \"weighted\":\n",
    "            countext_counts = {x:context_counts[x]/(len(context_tokens)+1) for x in context_counts.keys()} \n",
    "        feature_vector_dict.update(context_counts)\n",
    "    \n",
    "    \n",
    "    for f,v in feature_vector_dict.items():\n",
    "        feat = f\n",
    "        if f in [\"subject\", \"speaker\",\n",
    "                      \"speaker_job_title\",\n",
    "                      \"state_info\",\n",
    "                      \"party_affiliation\",\n",
    "                      \"total_barely_true_counts\",\n",
    "                      \"total_false_counts\",\n",
    "                      \"total_half_true_counts\",\n",
    "                      \"total_mostly_true_counts\",\n",
    "                      \"total_pants_on_fire_counts\"]:\n",
    "            feat = f + \"_\" + str(v)\n",
    "                \n",
    "        if not feat in global_feature_dict:\n",
    "            global_feature_dict[feat] = 1\n",
    "        else:\n",
    "            global_feature_dict[feat] +=1\n",
    "            \n",
    "    return feature_vector_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'convert_usernames': False, 'separate_out_punctuation': False, 'convert_number_words_to_digits': False, 'convert_numbers': False, 'remove_punctuation': True, 'convert_to_lowercase': False, 'remove_stopwords': True, 'apply_lemmatization': True}\n",
      "{'subject': True, 'speaker': True, 'speaker_job_title': True, 'state_info': True, 'party_affiliation': True, 'total_barely_true_counts': True, 'total_false_counts': True, 'total_half_true_counts': True, 'total_mostly_true_counts': True, 'total_pants_on_fire_counts': True, 'context': True}\n",
      "weights counts\n",
      "n 4\n",
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 10241 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n",
      "({'1@Says': 1, '1@Annies': 1, '1@List': 1, '1@political': 1, '1@group': 1, '1@support': 1, '1@thirdtrimester': 1, '1@abortion': 1, '1@demand': 1, '1@</s>': 1, '2@<s> Says': 1, '2@Says Annies': 1, '2@Annies List': 1, '2@List political': 1, '2@political group': 1, '2@group support': 1, '2@support thirdtrimester': 1, '2@thirdtrimester abortion': 1, '2@abortion demand': 1, '2@demand </s>': 1, '3@<s> <s> Says': 1, '3@<s> Says Annies': 1, '3@Says Annies List': 1, '3@Annies List political': 1, '3@List political group': 1, '3@political group support': 1, '3@group support thirdtrimester': 1, '3@support thirdtrimester abortion': 1, '3@thirdtrimester abortion demand': 1, '3@abortion demand </s>': 1, '4@<s> <s> <s> Says': 1, '4@<s> <s> Says Annies': 1, '4@<s> Says Annies List': 1, '4@Says Annies List political': 1, '4@Annies List political group': 1, '4@List political group support': 1, '4@political group support thirdtrimester': 1, '4@group support thirdtrimester abortion': 1, '4@support thirdtrimester abortion demand': 1, '4@thirdtrimester abortion demand </s>': 1, 'subject': 'abortion', 'speaker': 'dwayne-bohac', 'speaker_job_title': 'State representative', 'state_info': 'Texas', 'party_affiliation': 'republican', 'total_barely_true_counts': '0', 'total_false_counts': '1', 'total_half_true_counts': '0', 'total_mostly_true_counts': '0', 'total_pants_on_fire_counts': '0', 'context_mailer': 1}, 'FAKE')\n",
      "After split, 10241 rawData, 8192 trainData, 2049 testData\n",
      "Training Samples: \n",
      "8192\n",
      "Features: \n",
      "325598\n",
      "Fold start on items 0 - 820\n",
      "Training Classifier...\n",
      "Fold start on items 820 - 1640\n",
      "Training Classifier...\n",
      "Fold start on items 1640 - 2460\n",
      "Training Classifier...\n",
      "Fold start on items 2460 - 3280\n",
      "Training Classifier...\n",
      "Fold start on items 3280 - 4100\n",
      "Training Classifier...\n",
      "Fold start on items 4100 - 4920\n",
      "Training Classifier...\n",
      "Fold start on items 4920 - 5740\n",
      "Training Classifier...\n",
      "Fold start on items 5740 - 6560\n",
      "Training Classifier...\n",
      "Fold start on items 6560 - 7380\n",
      "Training Classifier...\n",
      "Fold start on items 7380 - 8200\n",
      "Training Classifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7125313153231291, 0.7134050222275622, 0.7122348923890041]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try adding all features first\n",
    "extra_feature_switches = {k: True for k in header}\n",
    "print(preprocessing_switches)\n",
    "print(extra_feature_switches)\n",
    "print(\"weights\", _WEIGHT_)\n",
    "print(\"n\", _N_)\n",
    "# loading reviews\n",
    "# initialize global lists that will be appended to by the methods below\n",
    "raw_data = []          # the filtered data from the dataset file\n",
    "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "# references to the data files\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "# Do the actual stuff (i.e. call the functions we've made)\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "# You do the cross validation on the 80% (training data)\n",
    "# We print the number of training samples and the number of features before the split\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "# let's look at the representation of the first instance of training:\n",
    "print(train_data[0])\n",
    "\n",
    "# We print the number of training samples and the number of features after the split\n",
    "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n",
    "\n",
    "cross_validate(train_data, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Feature ablation of extra features\n",
    "* There is a significant improvement using all the features at **0.712** (from 0.605 without access to these features in Q5) Can we get a better score by removing some of the extra features and not using all of them, as some may not be useful/harmful to generalization? Try all combinations, only by using the first fold due to number of combinations (2 to the number of extra features).\n",
    "* Always include context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # takes some time as 2 ** num_extra_features - only set to True to do search\n",
    "    combos = [list(p) for p in powerset(header[:-1])]  # always use context, just combination of others\n",
    "    print(\"trying\", len(combos), \"combinations\")\n",
    "    best_f_score = 0  # initial best mean accuracy to beat\n",
    "\n",
    "    results = []\n",
    "    print(\"using preprocessing switches\", preprocessing_switches)\n",
    "    print(\"weight\", _WEIGHT_)\n",
    "    print(\"n\", _N_)\n",
    "\n",
    "\n",
    "    raw_data = []          # the filtered data from the dataset file\n",
    "    # references to the data files\n",
    "    data_file_path = 'fake_news.tsv'\n",
    "\n",
    "    # Do the actual stuff (i.e. call the functions we've made)\n",
    "    # We parse the dataset and put it in a raw data list\n",
    "    print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "          \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "    load_data(data_file_path) \n",
    "\n",
    "    # We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "    # You do the cross validation on the 80% (training data)\n",
    "    # We print the number of training samples and the number of features before the split\n",
    "    print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "          \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "    # try all different extra feature switches - 10**2 (1024 settings, will take some time!)\n",
    "    for switches in combos:\n",
    "        #preprocessing_switches = {k : False for k in preprocessing_switches.keys()}\n",
    "        #for switch in switches:\n",
    "        #    preprocessing_switches[switch] = True\n",
    "        #print(\"*\" * 30)\n",
    "        extra_feature_switches = {k : False for k in header}\n",
    "        for switch in switches:\n",
    "            extra_feature_switches[switch] = True\n",
    "        extra_feature_switches[\"context\"] = True  # always use context\n",
    "        print(extra_feature_switches)\n",
    "        #print(\"*\" * 30)\n",
    "\n",
    "\n",
    "        #print(extra_feature_switches)\n",
    "        # loading reviews\n",
    "        # initialize global lists that will be appended to by the methods below\n",
    "        #raw_data = []          # the filtered data from the dataset file\n",
    "        train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "        test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "        split_and_preprocess_data(0.8)\n",
    "\n",
    "        # let's look at the representation of the first instance of training:\n",
    "        print(train_data[0])\n",
    "\n",
    "        # We print the number of training samples and the number of features after the split\n",
    "        print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "              \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n",
    "\n",
    "\n",
    "        all_scores = cross_validate(train_data, 10, first_fold_only=True)  # just do first fold\n",
    "        f_score = all_scores[2]\n",
    "        print(f_score)\n",
    "        results.append([(k,v) for k,v in extra_feature_switches.items()] + all_scores)\n",
    "        print(\"*\" * 40)\n",
    "        #plot_heat_map_similarity(df)\n",
    "        if f_score >= best_f_score:\n",
    "            best_f_score = f_score\n",
    "            best_switches = switches\n",
    "\n",
    "    # make the preprocessing switches the best one:\n",
    "    extra_feature_switches = {k : False for k in extra_feature_switches.keys()}\n",
    "    for switch in best_switches:\n",
    "        extra_feature_switches[switch] = True\n",
    "    extra_feature_switches['context'] = True # always use context\n",
    "    print(\"*\" * 50)\n",
    "    print(\"best f-score\", best_f_score)\n",
    "    print(\"best combo\", extra_feature_switches) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job_title</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>total_barely_true_counts</th>\n",
       "      <th>total_false_counts</th>\n",
       "      <th>total_half_true_counts</th>\n",
       "      <th>total_mostly_true_counts</th>\n",
       "      <th>total_pants_on_fire_counts</th>\n",
       "      <th>context</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.744939</td>\n",
       "      <td>0.746341</td>\n",
       "      <td>0.745351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.742767</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.743173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>0.742683</td>\n",
       "      <td>0.741319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.740950</td>\n",
       "      <td>0.742683</td>\n",
       "      <td>0.741319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.740019</td>\n",
       "      <td>0.741463</td>\n",
       "      <td>0.740454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.739007</td>\n",
       "      <td>0.740244</td>\n",
       "      <td>0.739437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.738596</td>\n",
       "      <td>0.740244</td>\n",
       "      <td>0.739015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.738596</td>\n",
       "      <td>0.740244</td>\n",
       "      <td>0.739015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.738025</td>\n",
       "      <td>0.739024</td>\n",
       "      <td>0.738413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.736400</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.736852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.736260</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.736710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.736131</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.736564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.736013</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.736415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.734262</td>\n",
       "      <td>0.735366</td>\n",
       "      <td>0.734680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.733942</td>\n",
       "      <td>0.735366</td>\n",
       "      <td>0.734404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.732950</td>\n",
       "      <td>0.734146</td>\n",
       "      <td>0.733389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.732253</td>\n",
       "      <td>0.734146</td>\n",
       "      <td>0.732660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.732379</td>\n",
       "      <td>0.732927</td>\n",
       "      <td>0.732625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.731988</td>\n",
       "      <td>0.732927</td>\n",
       "      <td>0.732368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.731988</td>\n",
       "      <td>0.732927</td>\n",
       "      <td>0.732368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.731809</td>\n",
       "      <td>0.732927</td>\n",
       "      <td>0.732234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.731641</td>\n",
       "      <td>0.732927</td>\n",
       "      <td>0.732097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729934</td>\n",
       "      <td>0.730488</td>\n",
       "      <td>0.730183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729538</td>\n",
       "      <td>0.730488</td>\n",
       "      <td>0.729924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729356</td>\n",
       "      <td>0.730488</td>\n",
       "      <td>0.729789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729185</td>\n",
       "      <td>0.730488</td>\n",
       "      <td>0.729650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729024</td>\n",
       "      <td>0.730488</td>\n",
       "      <td>0.729508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.728875</td>\n",
       "      <td>0.730488</td>\n",
       "      <td>0.729362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.728875</td>\n",
       "      <td>0.730488</td>\n",
       "      <td>0.729362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.728409</td>\n",
       "      <td>0.729268</td>\n",
       "      <td>0.728768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.628150</td>\n",
       "      <td>0.632927</td>\n",
       "      <td>0.629380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.628150</td>\n",
       "      <td>0.632927</td>\n",
       "      <td>0.629380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.628150</td>\n",
       "      <td>0.632927</td>\n",
       "      <td>0.629380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.627707</td>\n",
       "      <td>0.632927</td>\n",
       "      <td>0.628876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.627494</td>\n",
       "      <td>0.632927</td>\n",
       "      <td>0.628616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.627017</td>\n",
       "      <td>0.631707</td>\n",
       "      <td>0.628271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.626564</td>\n",
       "      <td>0.631707</td>\n",
       "      <td>0.627771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.626126</td>\n",
       "      <td>0.630488</td>\n",
       "      <td>0.627403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.626133</td>\n",
       "      <td>0.631707</td>\n",
       "      <td>0.627250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.625506</td>\n",
       "      <td>0.629268</td>\n",
       "      <td>0.626754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.624983</td>\n",
       "      <td>0.630488</td>\n",
       "      <td>0.626148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.624770</td>\n",
       "      <td>0.630488</td>\n",
       "      <td>0.625882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.624522</td>\n",
       "      <td>0.629268</td>\n",
       "      <td>0.625810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.624360</td>\n",
       "      <td>0.630488</td>\n",
       "      <td>0.625332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.623837</td>\n",
       "      <td>0.629268</td>\n",
       "      <td>0.625046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622518</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.623834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.621557</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.622841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.621106</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.622313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.621106</td>\n",
       "      <td>0.626829</td>\n",
       "      <td>0.622313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.620422</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.621738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.620422</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.621738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.619520</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.620667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.618410</td>\n",
       "      <td>0.623171</td>\n",
       "      <td>0.619780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.617936</td>\n",
       "      <td>0.624390</td>\n",
       "      <td>0.619007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.615419</td>\n",
       "      <td>0.620732</td>\n",
       "      <td>0.616809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.615177</td>\n",
       "      <td>0.620732</td>\n",
       "      <td>0.616546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.614939</td>\n",
       "      <td>0.620732</td>\n",
       "      <td>0.616278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.612918</td>\n",
       "      <td>0.618293</td>\n",
       "      <td>0.614345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.612657</td>\n",
       "      <td>0.619512</td>\n",
       "      <td>0.613765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.611501</td>\n",
       "      <td>0.618293</td>\n",
       "      <td>0.612675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1024 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  speaker  speaker_job_title  state_info  party_affiliation  \\\n",
       "0        True    False               True       False               True   \n",
       "1        True    False              False       False               True   \n",
       "2        True     True               True       False              False   \n",
       "3        True    False               True        True              False   \n",
       "4        True     True               True        True              False   \n",
       "5        True    False              False        True               True   \n",
       "6        True    False               True       False              False   \n",
       "7        True     True               True       False               True   \n",
       "8        True    False              False       False              False   \n",
       "9        True    False               True        True               True   \n",
       "10       True     True              False       False              False   \n",
       "11       True     True              False       False               True   \n",
       "12       True     True              False        True               True   \n",
       "13       True    False              False        True              False   \n",
       "14       True     True               True        True               True   \n",
       "15      False    False               True        True              False   \n",
       "16       True     True              False        True              False   \n",
       "17      False    False              False        True              False   \n",
       "18       True    False              False       False               True   \n",
       "19      False    False              False        True               True   \n",
       "20       True     True              False       False              False   \n",
       "21      False    False              False       False               True   \n",
       "22       True    False               True       False               True   \n",
       "23       True    False              False       False              False   \n",
       "24      False     True              False        True              False   \n",
       "25      False     True               True        True              False   \n",
       "26      False     True               True       False               True   \n",
       "27      False     True               True       False              False   \n",
       "28      False     True              False       False               True   \n",
       "29      False    False              False       False              False   \n",
       "...       ...      ...                ...         ...                ...   \n",
       "994     False    False               True        True               True   \n",
       "995      True     True              False        True               True   \n",
       "996      True    False               True        True              False   \n",
       "997      True    False               True        True               True   \n",
       "998      True     True              False        True              False   \n",
       "999     False    False              False        True              False   \n",
       "1000     True     True              False       False              False   \n",
       "1001    False    False               True       False              False   \n",
       "1002    False     True               True        True               True   \n",
       "1003    False    False              False       False              False   \n",
       "1004     True    False               True        True              False   \n",
       "1005    False     True              False       False              False   \n",
       "1006    False     True              False        True               True   \n",
       "1007     True     True              False       False              False   \n",
       "1008    False     True               True       False              False   \n",
       "1009     True    False              False        True              False   \n",
       "1010    False     True              False        True              False   \n",
       "1011    False    False              False       False               True   \n",
       "1012     True    False              False       False              False   \n",
       "1013     True     True               True       False              False   \n",
       "1014     True     True               True        True              False   \n",
       "1015     True    False              False       False               True   \n",
       "1016    False    False               True        True              False   \n",
       "1017     True    False               True       False               True   \n",
       "1018     True    False              False        True              False   \n",
       "1019    False     True               True        True              False   \n",
       "1020    False    False               True       False              False   \n",
       "1021     True    False               True       False              False   \n",
       "1022     True    False              False       False              False   \n",
       "1023    False    False              False       False              False   \n",
       "\n",
       "      total_barely_true_counts  total_false_counts  total_half_true_counts  \\\n",
       "0                         True                True                    True   \n",
       "1                         True                True                    True   \n",
       "2                         True                True                    True   \n",
       "3                         True                True                    True   \n",
       "4                         True                True                    True   \n",
       "5                         True                True                    True   \n",
       "6                         True                True                    True   \n",
       "7                         True                True                    True   \n",
       "8                         True                True                    True   \n",
       "9                         True                True                    True   \n",
       "10                        True                True                    True   \n",
       "11                        True                True                    True   \n",
       "12                        True                True                    True   \n",
       "13                        True                True                    True   \n",
       "14                        True                True                    True   \n",
       "15                        True                True                    True   \n",
       "16                        True                True                    True   \n",
       "17                        True                True                    True   \n",
       "18                        True                True                    True   \n",
       "19                        True                True                    True   \n",
       "20                        True                True                    True   \n",
       "21                        True                True                    True   \n",
       "22                        True                True                    True   \n",
       "23                        True                True                    True   \n",
       "24                        True                True                    True   \n",
       "25                        True                True                    True   \n",
       "26                        True                True                    True   \n",
       "27                        True                True                    True   \n",
       "28                        True                True                    True   \n",
       "29                        True                True                    True   \n",
       "...                        ...                 ...                     ...   \n",
       "994                      False               False                   False   \n",
       "995                      False               False                   False   \n",
       "996                      False               False                   False   \n",
       "997                      False               False                   False   \n",
       "998                      False               False                   False   \n",
       "999                      False               False                   False   \n",
       "1000                     False               False                   False   \n",
       "1001                     False               False                   False   \n",
       "1002                     False               False                   False   \n",
       "1003                     False               False                   False   \n",
       "1004                     False               False                   False   \n",
       "1005                     False               False                   False   \n",
       "1006                     False               False                   False   \n",
       "1007                     False               False                   False   \n",
       "1008                     False               False                   False   \n",
       "1009                     False               False                   False   \n",
       "1010                     False               False                   False   \n",
       "1011                     False               False                   False   \n",
       "1012                     False               False                   False   \n",
       "1013                     False               False                   False   \n",
       "1014                     False               False                   False   \n",
       "1015                     False               False                   False   \n",
       "1016                     False               False                   False   \n",
       "1017                     False               False                   False   \n",
       "1018                     False               False                   False   \n",
       "1019                     False               False                   False   \n",
       "1020                     False               False                   False   \n",
       "1021                     False               False                   False   \n",
       "1022                     False               False                   False   \n",
       "1023                     False               False                   False   \n",
       "\n",
       "      total_mostly_true_counts  total_pants_on_fire_counts  context         p  \\\n",
       "0                         True                        True     True  0.744939   \n",
       "1                         True                        True     True  0.742767   \n",
       "2                         True                        True     True  0.740950   \n",
       "3                         True                        True     True  0.740950   \n",
       "4                         True                        True     True  0.740019   \n",
       "5                         True                        True     True  0.739007   \n",
       "6                         True                        True     True  0.738596   \n",
       "7                         True                        True     True  0.738596   \n",
       "8                         True                        True     True  0.738025   \n",
       "9                         True                        True     True  0.736400   \n",
       "10                        True                        True     True  0.736260   \n",
       "11                        True                        True     True  0.736131   \n",
       "12                        True                        True     True  0.736013   \n",
       "13                        True                        True     True  0.734262   \n",
       "14                        True                        True     True  0.733942   \n",
       "15                        True                        True     True  0.732950   \n",
       "16                        True                        True     True  0.732253   \n",
       "17                        True                        True     True  0.732379   \n",
       "18                        True                       False     True  0.731988   \n",
       "19                        True                        True     True  0.731988   \n",
       "20                        True                       False     True  0.731809   \n",
       "21                        True                        True     True  0.731641   \n",
       "22                        True                       False     True  0.729934   \n",
       "23                        True                       False     True  0.729538   \n",
       "24                        True                        True     True  0.729356   \n",
       "25                        True                        True     True  0.729185   \n",
       "26                        True                        True     True  0.729024   \n",
       "27                        True                        True     True  0.728875   \n",
       "28                        True                        True     True  0.728875   \n",
       "29                        True                        True     True  0.728409   \n",
       "...                        ...                         ...      ...       ...   \n",
       "994                      False                       False     True  0.628150   \n",
       "995                      False                       False     True  0.628150   \n",
       "996                      False                        True     True  0.628150   \n",
       "997                      False                       False     True  0.627707   \n",
       "998                      False                       False     True  0.627494   \n",
       "999                      False                       False     True  0.627017   \n",
       "1000                     False                        True     True  0.626564   \n",
       "1001                     False                        True     True  0.626126   \n",
       "1002                     False                       False     True  0.626133   \n",
       "1003                     False                        True     True  0.625506   \n",
       "1004                     False                       False     True  0.624983   \n",
       "1005                     False                       False     True  0.624770   \n",
       "1006                     False                       False     True  0.624522   \n",
       "1007                     False                       False     True  0.624360   \n",
       "1008                     False                       False     True  0.623837   \n",
       "1009                     False                        True     True  0.622518   \n",
       "1010                     False                       False     True  0.621557   \n",
       "1011                     False                       False     True  0.621106   \n",
       "1012                     False                        True     True  0.621106   \n",
       "1013                     False                       False     True  0.620422   \n",
       "1014                     False                       False     True  0.620422   \n",
       "1015                     False                       False     True  0.619520   \n",
       "1016                     False                       False     True  0.618410   \n",
       "1017                     False                       False     True  0.617936   \n",
       "1018                     False                       False     True  0.615419   \n",
       "1019                     False                       False     True  0.615177   \n",
       "1020                     False                       False     True  0.614939   \n",
       "1021                     False                       False     True  0.612918   \n",
       "1022                     False                       False     True  0.612657   \n",
       "1023                     False                       False     True  0.611501   \n",
       "\n",
       "             r   f-score  \n",
       "0     0.746341  0.745351  \n",
       "1     0.743902  0.743173  \n",
       "2     0.742683  0.741319  \n",
       "3     0.742683  0.741319  \n",
       "4     0.741463  0.740454  \n",
       "5     0.740244  0.739437  \n",
       "6     0.740244  0.739015  \n",
       "7     0.740244  0.739015  \n",
       "8     0.739024  0.738413  \n",
       "9     0.737805  0.736852  \n",
       "10    0.737805  0.736710  \n",
       "11    0.737805  0.736564  \n",
       "12    0.737805  0.736415  \n",
       "13    0.735366  0.734680  \n",
       "14    0.735366  0.734404  \n",
       "15    0.734146  0.733389  \n",
       "16    0.734146  0.732660  \n",
       "17    0.732927  0.732625  \n",
       "18    0.732927  0.732368  \n",
       "19    0.732927  0.732368  \n",
       "20    0.732927  0.732234  \n",
       "21    0.732927  0.732097  \n",
       "22    0.730488  0.730183  \n",
       "23    0.730488  0.729924  \n",
       "24    0.730488  0.729789  \n",
       "25    0.730488  0.729650  \n",
       "26    0.730488  0.729508  \n",
       "27    0.730488  0.729362  \n",
       "28    0.730488  0.729362  \n",
       "29    0.729268  0.728768  \n",
       "...        ...       ...  \n",
       "994   0.632927  0.629380  \n",
       "995   0.632927  0.629380  \n",
       "996   0.632927  0.629380  \n",
       "997   0.632927  0.628876  \n",
       "998   0.632927  0.628616  \n",
       "999   0.631707  0.628271  \n",
       "1000  0.631707  0.627771  \n",
       "1001  0.630488  0.627403  \n",
       "1002  0.631707  0.627250  \n",
       "1003  0.629268  0.626754  \n",
       "1004  0.630488  0.626148  \n",
       "1005  0.630488  0.625882  \n",
       "1006  0.629268  0.625810  \n",
       "1007  0.630488  0.625332  \n",
       "1008  0.629268  0.625046  \n",
       "1009  0.626829  0.623834  \n",
       "1010  0.626829  0.622841  \n",
       "1011  0.626829  0.622313  \n",
       "1012  0.626829  0.622313  \n",
       "1013  0.625610  0.621738  \n",
       "1014  0.625610  0.621738  \n",
       "1015  0.625610  0.620667  \n",
       "1016  0.623171  0.619780  \n",
       "1017  0.624390  0.619007  \n",
       "1018  0.620732  0.616809  \n",
       "1019  0.620732  0.616546  \n",
       "1020  0.620732  0.616278  \n",
       "1021  0.618293  0.614345  \n",
       "1022  0.619512  0.613765  \n",
       "1023  0.618293  0.612675  \n",
       "\n",
       "[1024 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's display all the results in a pandas dataframe\n",
    "import pandas as pd\n",
    "if False:  # set as False if above search not run\n",
    "    results = sorted(results, key=lambda x:x[-1], reverse=True) # sort results from best to worst f-score\n",
    "    df = pd.DataFrame([[x[1] for x in row[:-3]] + row[-3:] for row in results],\n",
    "                  columns=[x[0] for x in results[0][:-3]] + [\"p\", \"r\", \"f-score\"])\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 0.6809504867698621\n",
      "speaker 0.6818461517997764\n",
      "speaker_job_title 0.6810798327315704\n",
      "state_info 0.6802716717037852\n",
      "party_affiliation 0.6814256778007377\n",
      "total_barely_true_counts 0.6896806148714493\n",
      "total_false_counts 0.6962211080706227\n",
      "total_half_true_counts 0.6896977875955431\n",
      "total_mostly_true_counts 0.6946992152837231\n",
      "total_pants_on_fire_counts 0.6843474185747227\n",
      "context 0.6807127926057801\n"
     ]
    }
   ],
   "source": [
    "# which feature being true tends to help more?\n",
    "if False:  # set as False if above search not run\n",
    "    for key in extra_feature_switches.keys():\n",
    "        print(key, sum(df[df[key]==True]['f-score']) / len(df[df[key]==True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments on extra features (for report)\n",
    "* Using a single fold train/heldout set-up using the best settings found in Q5 showed that the best combination of features was using **all features except 'speaker' and 'state_info'**. As these are speaker identification features, it is perhaps unsurprising they are not as useful text features when encountering new users compared to more generalizable features.\n",
    "* In this setting at least, all of the counts of previous real/fake news statements were in the best setting, showing the importance of previous behaviour. speaker_job_title and party_affiliation were also there, showing there are generalizations to be made about the type of user which are helpful.\n",
    "* The **total_false_counts** is the most useful feature in combination with the others, followed by the **total_mostly_true_counts**, showing the utility of knowing **the speaker/user's previous behaviour with fake news**. All the counts of previous fake/real news behaviour could have been collapsed into just two sets of counts using the multiple label -> {FAKE, REAL} mapping we're using for classification, but not certain of the difference that would make. The speaker identification features (speaker, speaker_job_title, state_info_part_affiliation) and subject were overall less useful in combination with others than the count features.\n",
    "* This result may not hold when using other features/weightings/hyper-parameter optimisations and may need to be re-done for a final global best model. Also, this was done on a single train/heldout fold so danger of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best setting from search\n",
    "extra_feature_switches = {'subject': True, 'speaker': False, 'speaker_job_title': True,\n",
    "                          'state_info': False, 'party_affiliation': True, 'total_barely_true_counts': True,\n",
    "                          'total_false_counts': True, 'total_half_true_counts': True,\n",
    "                          'total_mostly_true_counts': True, 'total_pants_on_fire_counts': True, 'context': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py37/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda2/envs/py37/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1],\n",
       "                          'max_iter': [1, 5, 10, 50, 100, 500, 1000, 5000]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeating from Q5: Final hyperparameter tuning of the linearSVC on cross-val across the training data\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "parameters = [{\n",
    "#'kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'], \n",
    "'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1],\n",
    "'max_iter': [1,5,10, 50, 100, 500, 1000, 5000]}]\n",
    "\n",
    "clf = GridSearchCV(\n",
    "        LinearSVC(), parameters, scoring='accuracy'\n",
    "    )\n",
    "\n",
    "clf.fit(DictVectorizer().fit_transform([x[0] for x in train_data]), [x[1] for x in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.005, 'max_iter': 10}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_C_ = clf.best_params_[\"C\"]\n",
    "_MAX_ITER_ = clf.best_params_[\"max_iter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(data):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([\n",
    "     ('svc', LinearSVC(C=_C_, max_iter=_MAX_ITER_))])\n",
    "    return SklearnClassifier(pipeline).train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'convert_usernames': False, 'separate_out_punctuation': False, 'convert_number_words_to_digits': False, 'convert_numbers': False, 'remove_punctuation': True, 'convert_to_lowercase': False, 'remove_stopwords': True, 'apply_lemmatization': True}\n",
      "{'subject': True, 'speaker': False, 'speaker_job_title': True, 'state_info': False, 'party_affiliation': True, 'total_barely_true_counts': True, 'total_false_counts': True, 'total_half_true_counts': True, 'total_mostly_true_counts': True, 'total_pants_on_fire_counts': True, 'context': True}\n",
      "weights counts\n",
      "n 4\n",
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 10241 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n",
      "({'1@Says': 1, '1@Annies': 1, '1@List': 1, '1@political': 1, '1@group': 1, '1@support': 1, '1@thirdtrimester': 1, '1@abortion': 1, '1@demand': 1, '1@</s>': 1, '2@<s> Says': 1, '2@Says Annies': 1, '2@Annies List': 1, '2@List political': 1, '2@political group': 1, '2@group support': 1, '2@support thirdtrimester': 1, '2@thirdtrimester abortion': 1, '2@abortion demand': 1, '2@demand </s>': 1, '3@<s> <s> Says': 1, '3@<s> Says Annies': 1, '3@Says Annies List': 1, '3@Annies List political': 1, '3@List political group': 1, '3@political group support': 1, '3@group support thirdtrimester': 1, '3@support thirdtrimester abortion': 1, '3@thirdtrimester abortion demand': 1, '3@abortion demand </s>': 1, '4@<s> <s> <s> Says': 1, '4@<s> <s> Says Annies': 1, '4@<s> Says Annies List': 1, '4@Says Annies List political': 1, '4@Annies List political group': 1, '4@List political group support': 1, '4@political group support thirdtrimester': 1, '4@group support thirdtrimester abortion': 1, '4@support thirdtrimester abortion demand': 1, '4@thirdtrimester abortion demand </s>': 1, 'subject': 'abortion', 'speaker_job_title': 'State representative', 'party_affiliation': 'republican', 'total_barely_true_counts': '0', 'total_false_counts': '1', 'total_half_true_counts': '0', 'total_mostly_true_counts': '0', 'total_pants_on_fire_counts': '0', 'context_mailer': 1}, 'FAKE')\n",
      "After split, 10241 rawData, 8192 trainData, 2049 testData\n",
      "Training Samples: \n",
      "8192\n",
      "Features: \n",
      "325598\n",
      "Fold start on items 0 - 820\n",
      "Training Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py37/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold start on items 820 - 1640\n",
      "Training Classifier...\n",
      "Fold start on items 1640 - 2460\n",
      "Training Classifier...\n",
      "Fold start on items 2460 - 3280\n",
      "Training Classifier...\n",
      "Fold start on items 3280 - 4100\n",
      "Training Classifier...\n",
      "Fold start on items 4100 - 4920\n",
      "Training Classifier...\n",
      "Fold start on items 4920 - 5740\n",
      "Training Classifier...\n",
      "Fold start on items 5740 - 6560\n",
      "Training Classifier...\n",
      "Fold start on items 6560 - 7380\n",
      "Training Classifier...\n",
      "Fold start on items 7380 - 8200\n",
      "Training Classifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7284071503052327, 0.7293866394328967, 0.7270919540905876]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUESTION 3 - Make sure there is a function call here to the\n",
    "# crossValidate function on the training set to get your results\n",
    "print(preprocessing_switches)\n",
    "print(extra_feature_switches)\n",
    "print(\"weights\", _WEIGHT_)\n",
    "print(\"n\", _N_)\n",
    "# loading reviews\n",
    "# initialize global lists that will be appended to by the methods below\n",
    "raw_data = []          # the filtered data from the dataset file\n",
    "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "# references to the data files\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "# Do the actual stuff (i.e. call the functions we've made)\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "# You do the cross validation on the 80% (training data)\n",
    "# We print the number of training samples and the number of features before the split\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "# let's look at the representation of the first instance of training:\n",
    "print(train_data[0])\n",
    "\n",
    "# We print the number of training samples and the number of features after the split\n",
    "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n",
    "\n",
    "cross_validate(train_data, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system has improved to a **0.727** f-score (from 0.712) through optimized feature sets and also hyper-parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'1@The': 1, '1@Bush': 1, '1@tax': 1, '1@cut': 1, '1@helped': 1, '1@create': 1, '1@substantial': 1, '1@part': 1, '1@deficit': 1, '1@</s>': 1, '2@<s> The': 1, '2@The Bush': 1, '2@Bush tax': 1, '2@tax cut': 1, '2@cut helped': 1, '2@helped create': 1, '2@create substantial': 1, '2@substantial part': 1, '2@part deficit': 1, '2@deficit </s>': 1, '3@<s> <s> The': 1, '3@<s> The Bush': 1, '3@The Bush tax': 1, '3@Bush tax cut': 1, '3@tax cut helped': 1, '3@cut helped create': 1, '3@helped create substantial': 1, '3@create substantial part': 1, '3@substantial part deficit': 1, '3@part deficit </s>': 1, '4@<s> <s> <s> The': 1, '4@<s> <s> The Bush': 1, '4@<s> The Bush tax': 1, '4@The Bush tax cut': 1, '4@Bush tax cut helped': 1, '4@tax cut helped create': 1, '4@cut helped create substantial': 1, '4@helped create substantial part': 1, '4@create substantial part deficit': 1, '4@substantial part deficit </s>': 1, 'subject': 'bush-administration,deficit,taxes', 'speaker_job_title': 'U.S. representative', 'party_affiliation': 'democrat', 'total_barely_true_counts': '1', 'total_false_counts': '3', 'total_half_true_counts': '4', 'total_mostly_true_counts': '6', 'total_pants_on_fire_counts': '0', 'context_radio': 1, 'context_interview': 1}, 'REAL')\n",
      "Training Classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.72      0.61      0.66       926\n",
      "        REAL       0.71      0.80      0.76      1123\n",
      "\n",
      "    accuracy                           0.72      2049\n",
      "   macro avg       0.72      0.71      0.71      2049\n",
      "weighted avg       0.72      0.72      0.71      2049\n",
      "\n",
      "Done training!\n",
      "Precision: 0.715677\n",
      "Recall: 0.715471\n",
      "F Score:0.712285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py37/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Finally, check the accuracy of your classifier by training on all the tranin data\n",
    "# and testing on the test set\n",
    "# Will only work once all functions are complete\n",
    "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
    "if functions_complete:\n",
    "    print(test_data[0])   # have a look at the first test data instance\n",
    "    classifier = train_classifier(train_data)  # train the classifier\n",
    "    test_true = [t[1] for t in test_data]   # get the ground-truth labels from the data\n",
    "    test_pred = predict_labels([x[0] for x in test_data], classifier)  # classify the test data to get predicted labels\n",
    "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='weighted') # evaluate\n",
    "    report = classification_report(test_true, test_pred, output_dict=True)\n",
    "    print(classification_report(test_true, test_pred))\n",
    "    print(\"Done training!\")\n",
    "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
